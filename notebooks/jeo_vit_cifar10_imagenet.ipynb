{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import PIL\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import timm\n",
    "import math\n",
    "import copy\n",
    "import torch\n",
    "import pickle\n",
    "import logging\n",
    "import fnmatch\n",
    "import argparse\n",
    "import itertools\n",
    "import torchvision\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "# from apex import amp\n",
    "import seaborn as sns\n",
    "import albumentations\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "import scikitplot as skplt\n",
    "from sklearn import metrics\n",
    "import torch.optim as optim\n",
    "from timm import create_model\n",
    "from datetime import datetime\n",
    "from timm.data.loader import *\n",
    "from torchvision import models\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "# from cutmix.cutmix import CutMix\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from torch.optim import lr_scheduler\n",
    "#from pytorch_metric_learning import loss\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from timm.models.layers.activations import *\n",
    "from timm.utils import accuracy, AverageMeter\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "# from apex.parallel import convert_syncbn_model\n",
    "from timm.utils import ApexScaler, NativeScaler\n",
    "# from cutmix.utils import CutMixCrossEntropyLoss\n",
    "from timm.models.registry import register_model\n",
    "from timm.models.vision_transformer import VisionTransformer\n",
    "\n",
    "# import VIT_imagenet.VIT as v\n",
    "from collections import OrderedDict, defaultdict\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "from timm.models.resnet import resnet26d, resnet50d\n",
    "from torchvision import transforms, models, datasets\n",
    "from timm.models.helpers import build_model_with_cfg\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from randaugment import RandAugment, ImageNetPolicy, Cutout\n",
    "# from apex.parallel import DistributedDataParallel as ApexDDP\n",
    "from timm.models.layers import DropPath, to_2tuple, trunc_normal_\n",
    "from timm.data import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n",
    "from timm.loss import LabelSmoothingCrossEntropy, SoftTargetCrossEntropy\n",
    "from timm.models.efficientnet import efficientnet_b0, efficientnet_b1, efficientnet_b2, efficientnet_b3\n",
    "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score, roc_curve, auc, roc_auc_score\n",
    "#from timm.data import Dataset, DatasetTar, RealLabelsImagenet, create_loader, Mixup, FastCollateMixup, AugMixDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 179460,
     "status": "ok",
     "timestamp": 1588213186502,
     "user": {
      "displayName": "DUONG TUAN LINH",
      "photoUrl": "",
      "userId": "10844282398210252241"
     },
     "user_tz": -420
    },
    "id": "yyGpxuktB96O",
    "outputId": "584ea32f-dbe1-4465-8e60-e0f4e5c96a6f"
   },
   "outputs": [],
   "source": [
    "imagenet_dir = '/scratch/work/public/imagenet/train'\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "batch_size = 50\n",
    "num_epochs = 500\n",
    "# lr = 0.001\n",
    "lr = 1e-4\n",
    "beta = 1\n",
    "step_size = 130\n",
    "img_size = 224\n",
    "test_size = 224\n",
    "\n",
    "\n",
    "mean = [0.485] \n",
    "std = [0.229]\n",
    "num_workers = 4\n",
    "# Define your transforms for the training and testing sets\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.CenterCrop(img_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std),\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.CenterCrop(test_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std),\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.CenterCrop(test_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std),\n",
    "    ])\n",
    "}\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split_size = 1000\n",
    "val_split_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_train = datasets.ImageFolder(imagenet_dir, transform=data_transforms['train']\n",
    "                                          )\n",
    "\n",
    "\n",
    "#split into train and val samples \n",
    "train_split = torch.utils.data.random_split(imagenet_train, \n",
    "                                            [train_split_size, len(imagenet_train)-train_split_size])[0]\n",
    "\n",
    "val_split = torch.utils.data.random_split(imagenet_train, \n",
    "                                            [len(imagenet_train)-val_split_size, val_split_size])[1]\n",
    "\n",
    "\n",
    "# get train and val dataloaders\n",
    "train = torch.utils.data.DataLoader(train_split, batch_size = batch_size, shuffle=True,\n",
    "                                    num_workers=num_workers)\n",
    "\n",
    "val = torch.utils.data.DataLoader(val_split, batch_size = batch_size, shuffle=True,\n",
    "                                    num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch0 = next(iter(train))\n",
    "batch0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(batch0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image0 = batch0[0][0]\n",
    "label0 = batch0[1][0]\n",
    "print('image:',image0)\n",
    "print('label:',label0)\n",
    "print('image size:',image0.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch1 = next(iter(val))\n",
    "batch1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(batch1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image1 = batch1[0][0]\n",
    "label1 = batch1[1][0]\n",
    "print('image:',image1)\n",
    "print('label:',label1)\n",
    "print('image size:',image1.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CIFAR 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from https://github.com/jeonggunlee/Vision-Transformer-Study/blob/main/Vision_Transformer_Cifar10.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch = 4\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split_size = 10000\n",
    "val_split_size = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "print('==> Preparing data..')\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.CenterCrop(32),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "cifar_train = torchvision.datasets.CIFAR10(root='../data', train=True, download=True, transform=transform_train)\n",
    "cifar_test = torchvision.datasets.CIFAR10(root='../data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "#split into train and val samples \n",
    "# cifar_train_split = torch.utils.data.random_split(cifar_train, \n",
    "#                                             [train_split_size, len(cifar_train)-train_split_size])[0]\n",
    "\n",
    "# cifar_val_split = torch.utils.data.random_split(cifar_train, \n",
    "#                                             [len(cifar_train)-val_split_size, val_split_size])[1]\n",
    "\n",
    "# train and val dataloaders\n",
    "trainloader = torch.utils.data.DataLoader(cifar_train, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "testloader = torch.utils.data.DataLoader(cifar_test, batch_size=100, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CIFAR Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch2 = next(iter(trainloader))\n",
    "batch2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(batch2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch2[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch2[1].size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CIFAR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_model = VisionTransformer(\n",
    "                                img_size = 32,\n",
    "                                patch_size = patch,\n",
    "                                num_classes = 10,\n",
    "                                embed_dim = 512,\n",
    "                                depth = 6,\n",
    "                                num_heads = 8,\n",
    "#                                 mlp_dim = 512,\n",
    "#                                 dropout = 0.1,\n",
    "#                                 emb_dropout = 0.1\n",
    "                                )\n",
    "cifar_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in cifar_model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cifar_model.parameters(), lr=lr,)\n",
    "cifar_model.to(device)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "count = count_parameters(cifar_model)\n",
    "print(\"The number of parameters of the model is:\", count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 226461,
     "status": "ok",
     "timestamp": 1588213233520,
     "user": {
      "displayName": "DUONG TUAN LINH",
      "photoUrl": "",
      "userId": "10844282398210252241"
     },
     "user_tz": -420
    },
    "id": "L9jdFtBjSAE6",
    "outputId": "f0f393c5-4369-422c-9aef-fc290ccc941d"
   },
   "outputs": [],
   "source": [
    "model = VisionTransformer()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 226454,
     "status": "ok",
     "timestamp": 1588213233520,
     "user": {
      "displayName": "DUONG TUAN LINH",
      "photoUrl": "",
      "userId": "10844282398210252241"
     },
     "user_tz": -420
    },
    "id": "w6QP4CFPBNzg",
    "outputId": "6beb0600-5fdf-4ae6-a216-40c32a13bb9f"
   },
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr,)\n",
    "model.to(device)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "count = count_parameters(model)\n",
    "print(\"The number of parameters of the model is:\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, criterion, optimizer, num_epochs=100):\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_targets = 0\n",
    "    best_acc = 0\n",
    "\n",
    "    for e in range(num_epochs):\n",
    "\n",
    "        epoch_loss = 0.0\n",
    "        epoch_correct = 0\n",
    "        epoch_targets = 0\n",
    "\n",
    "        for i, data in enumerate(dataloader, 0):\n",
    "            # extract inputs and labels\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # zero parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # set model to training mode\n",
    "            model.train()\n",
    "\n",
    "            # forward pass\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # compute loss\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # backprop\n",
    "            loss.backward()\n",
    "\n",
    "            # optimizer step\n",
    "            optimizer.step()\n",
    "\n",
    "            # getting outputs in true/false \n",
    "            _, preds = outputs.max(1)\n",
    "    #         _, preds = torch.max(outputs, 1)\n",
    "\n",
    "\n",
    "            # ------------ EVALUATION -----------\n",
    "\n",
    "            # compute number of correct predictions\n",
    "            correct = torch.sum(preds == labels.data)\n",
    "\n",
    "            # update correct counters\n",
    "            epoch_correct += correct\n",
    "            total_correct += correct\n",
    "\n",
    "            # update loss counters\n",
    "            epoch_loss += loss.item()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # update target counters\n",
    "            epoch_targets += labels.size(0)\n",
    "            total_targets += labels.size(0)\n",
    "\n",
    "\n",
    "            # calculate batch accuracy\n",
    "            batch_acc = correct / labels.size(0) * 100\n",
    "\n",
    "\n",
    "            # display every five batches\n",
    "            if i % 5 == 0:\n",
    "                print('Epoch: {0}/{1}, Batch: {2}/{3}, Loss: {4}, Acc: {5} %'.format(e+1,\n",
    "                                                                              num_epochs,\n",
    "                                                                              i,\n",
    "                                                                              len(dataloader),\n",
    "                                                                              loss.item(),\n",
    "                                                                              batch_acc       \n",
    "                                                                             ))\n",
    "\n",
    "        # calculate epoch metrics\n",
    "        epoch_loss = epoch_loss / len(dataloader)\n",
    "        epoch_acc = epoch_correct / epoch_targets * 100\n",
    "        \n",
    "        if epoch_acc > best_acc:\n",
    "            best_acc = epoch_acc\n",
    "\n",
    "        # calculate running accuracy\n",
    "        running_acc = total_correct / total_targets * 100\n",
    "\n",
    "        print('-'*20)\n",
    "        print('Epoch {0} finished. Accuracy: {1} %     Loss: {2}'.format(e+1,\n",
    "                                                                        epoch_acc,\n",
    "                                                                        epoch_loss,\n",
    "                                                                       ))\n",
    "        print('Running Accuracy: {0} %'.format(running_acc))\n",
    "\n",
    "        print('-'*20)\n",
    "\n",
    "\n",
    "    total_acc = total_correct / total_targets *100\n",
    "\n",
    "    print('Total accuracy: {0} %'.format(total_acc))\n",
    "    print('Best accuracy: {0} %'.format(best_acc))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(cifar_model, dataloader=trainloader, criterion=criterion, optimizer=optimizer, num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, dataloader, criterion):\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_targets = 0\n",
    "    best_acc = 0\n",
    "    \n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        # extract inputs and labels\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # set model to eval mode\n",
    "        model.eval()\n",
    "\n",
    "        # forward pass\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # compute loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # getting outputs in true/false \n",
    "        _, preds = outputs.max(1)\n",
    "    #         _, preds = torch.max(outputs, 1)\n",
    "\n",
    "\n",
    "        # ------------ EVALUATION -----------\n",
    "\n",
    "        # compute number of correct predictions\n",
    "        correct = torch.sum(preds == labels.data)\n",
    "\n",
    "        # update correct counter\n",
    "        total_correct += correct\n",
    "\n",
    "        # update loss counter\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # update target counter\n",
    "        total_targets += labels.size(0)\n",
    "\n",
    "\n",
    "        # calculate batch accuracy\n",
    "        batch_acc = correct / labels.size(0) * 100\n",
    "\n",
    "\n",
    "        # display every five batches\n",
    "        if i % 5 == 0:\n",
    "            print('Epoch: {0}/{1}, Batch: {2}/{3}, Loss: {4}, Acc: {5} %'.format('',\n",
    "                                                                          '',\n",
    "                                                                          i,\n",
    "                                                                          len(dataloader),\n",
    "                                                                          loss.item(),\n",
    "                                                                          batch_acc       \n",
    "                                                                         ))\n",
    "        \n",
    "        \n",
    "    total_acc = total_correct / total_targets *100\n",
    "\n",
    "    print('Total accuracy: {0} %'.format(total_acc))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(cifar_model, dataloader=testloader, criterion=criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Covid-19_EfficientNet_B0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
